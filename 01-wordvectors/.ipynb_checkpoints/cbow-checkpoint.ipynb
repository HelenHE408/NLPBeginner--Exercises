{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b403a6d-8d5a-4b0b-9452-61a3503025af",
   "metadata": {},
   "source": [
    "做word2vec训练的时候，应该选用“长文章”这样的语料，因为文章的上下文相关性是比较大的。如果采用“评论”这样的语料，语义重复太高，且强关联的vocabulary长度短。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9e3a67f-269a-42ca-af1a-5c740ca72eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import string\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import collections\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2df351e-4dc5-4cbc-af5f-8e9a0d4ea1c1",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0360f841-a85f-425a-ae1f-fb13b095a58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"news.txt\", \"r\")\n",
    "raw_text = []\n",
    "for line in file:\n",
    "    raw_text.append(line.strip())\n",
    "file.close()\n",
    "# 为了减少运算量少取几行\n",
    "raw_text = [raw_text[i] for i in range(5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dcba2c-32b3-49bb-acf7-58311a33848a",
   "metadata": {},
   "source": [
    "## data prerpocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c4c044a-e279-4129-86a5-60910d7a056d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dePunctuation(line):\n",
    "    line = line.translate(str.maketrans('', '', string.punctuation))\n",
    "    return line\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "    tokens = word_tokenize(text)\n",
    "    filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "    filtered_text = ' '.join(filtered_tokens)\n",
    "    return filtered_text\n",
    "\n",
    "\n",
    "def remove_lowFrequency(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    filtered_tokens = [word for word in tokens if word.lower() not in low_freq_vocab]\n",
    "    filtered_text = ' '.join(filtered_tokens)\n",
    "    return filtered_text\n",
    "\n",
    "def lowFrequency(text, threshold = 0):\n",
    "    # 处理corpus\n",
    "    tokens = [line.split() for line in text]\n",
    "    corpus = [token.lower() for sub_tokens in tokens for token in sub_tokens]\n",
    "    cha_count = collections.Counter(corpus)\n",
    "    cha_count_modified = {key: value / len(corpus) for key, value in cha_count.items()}\n",
    "    low_freq_vocab = [word for word, count in cha_count_modified.items() if count < threshold]\n",
    "    return low_freq_vocab\n",
    "\n",
    "def clean(text, type='word', stop = True):\n",
    "    cleaned_text = []\n",
    "    if type == 'word':\n",
    "        for line in text:\n",
    "            line = dePunctuation(line)\n",
    "            if stop:\n",
    "                line = remove_stopwords(line)\n",
    "            line = remove_lowFrequency(line)\n",
    "            cleaned_text.append(line)\n",
    "    elif type == 'char':\n",
    "        cleaned_text = [dePunctuation(line) for line in text]\n",
    "        cleaned_text = [token for line in cleaned_text for token in line]\n",
    "    cleaned_text = list(filter(lambda x: x != '', cleaned_text))\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0224278a-2379-405f-b21f-217ae26cc2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def context_center(clean_text, window_size=2):\n",
    "    flatten_text = ' '.join(clean_text).split()\n",
    "    data = []\n",
    "    for i, center in enumerate(flatten_text):\n",
    "        if (i-window_size>=0) and (i+window_size<len(flatten_text)):\n",
    "            context = [flatten_text[j] for j in range(i-window_size, i+window_size) \n",
    "                   if (j!=i)]\n",
    "            data.append((context, center))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44aae947-9aa0-4e81-8d4e-0064d70c5a17",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89f49fe-cf09-4de5-b4c0-7ec7e565c89c",
   "metadata": {},
   "source": [
    "## continues bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8c0a548-a1dd-4619-b4d7-74287f5a8621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_context_vector(context, word_to_ix):\n",
    "    idxs = [word_to_ix[w] for w in context]\n",
    "    return torch.tensor(idxs, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c1ba787-73b4-4c96-a494-1d3b925947bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOW(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size=128):\n",
    "        super(CBOW, self).__init__()\n",
    "\n",
    "        # 嵌入层的权重矩阵形状，随机初始化\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        # 全连接层的……，激活函数不改变维度\n",
    "        self.linear = nn.Linear(embedding_dim, hidden_size)\n",
    "        self.activation_function = nn.ReLU()\n",
    "\n",
    "        \n",
    "        # 输出层\n",
    "        self.linear_out = nn.Linear(hidden_size, vocab_size)\n",
    "        # dim=-1 表示对输入数据最后一维进行 softmax 变换\n",
    "        self.softmax_function = nn.LogSoftmax(dim = -1)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        # 将context每个单词embedded相加，得到的结果转化为行向量。-1表示自动计算列数\n",
    "        embeds = sum(self.embeddings(inputs)).view(1,-1)\n",
    "        \n",
    "        hidden = self.linear(embeds)\n",
    "        hidden = self.activation_function(hidden)\n",
    "        \n",
    "        out = self.linear_out(hidden)\n",
    "        out = self.softmax_function(out)\n",
    "        return out\n",
    "\n",
    "    def get_word_emdedding(self, word):\n",
    "        word = torch.tensor([word_to_ix[word]])\n",
    "        return self.embeddings(word).view(1,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a806984-40ff-4d51-9681-ccc979537bad",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d32e66a-92d5-467c-8b64-8b173b9ae65c",
   "metadata": {},
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e74839a3-d9fe-41c6-82a7-809fb9bc11f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 4\n",
    "\n",
    "low_freq_vocab = lowFrequency(raw_text, threshold = 0.0001)\n",
    "clean_text = clean(raw_text, type = 'word', stop = False)\n",
    "\n",
    "corpus = [line.split() for line in clean_text]\n",
    "corpus = [word for line in corpus for word in line]\n",
    "vocab = set(corpus)\n",
    "\n",
    "word_to_ix = {word:ix for ix, word in enumerate(vocab)}\n",
    "ix_to_word = {ix:word for ix, word in enumerate(vocab)}\n",
    "data = context_center(clean_text, window_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346eedfc-ac03-4e7d-9c21-baa42f7844c5",
   "metadata": {},
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3a140ae-f8cd-4118-9c52-7a7d3e791d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "EMDEDDING_DIM = 50\n",
    "vocab_size = len(vocab)\n",
    "hidden_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32b16dd6-5916-405d-9a57-20beaf5aa764",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CBOW(vocab_size, EMDEDDING_DIM, hidden_size)\n",
    "# 负对数似然损失（Negative Log Likelihood Loss）\n",
    "loss_function = nn.NLLLoss()\n",
    "# 使用随机梯度下降\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e7427b7-6d83-4d48-b716-0e9feeafb1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINING\n",
    "for epoch in range(50):\n",
    "    total_loss = 0\n",
    "\n",
    "    for context, center in data:\n",
    "        # 获得输入words的index\n",
    "        context_vector = make_context_vector(context, word_to_ix)\n",
    "        # 获得predict的概率分布\n",
    "        log_probs = model(context_vector)\n",
    "        # 损失函数\n",
    "        total_loss += loss_function(log_probs, torch.tensor([word_to_ix[center]]))\n",
    "\n",
    "    # 参数更新\n",
    "    # 在进行反向传播和更新参数之前，需要先清除之前计算得到的梯度值\n",
    "    optimizer.zero_grad()\n",
    "    # 计算损失函数关于模型参数的梯度，并将其存储在各自参数张量的 .grad 属性中\n",
    "    total_loss.backward()\n",
    "    # 优化器会根据梯度更新模型的参数值\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab61d5e5-b4a3-40a6-8c2c-3ff06297a90c",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2716ec4-d574-43e4-a988-38fa967866eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_context = raw_text[1]\n",
    "test_tokens = raw_text[1].split()[5:5+window_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37ae72a3-9bd5-48be-8278-b2ab4c9fe312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw text: \n",
      "The cryptocurrency and digital asset industry has once again been the focus of the worldwide media. This time, it is not about the promises of an inclusive future of finance but is related to a couple of court cases initiated or found to have come to a close in the past months.\n",
      "\n",
      "Context: \n",
      "['industry', 'has', 'once', 'again']\n",
      "\n",
      "Prediction: \n",
      "been\n"
     ]
    }
   ],
   "source": [
    "#TESTING\n",
    "context_vector = make_context_vector(test_tokens, word_to_ix)\n",
    "a = model(context_vector)\n",
    "\n",
    "#Print result\n",
    "print(f'Raw text: \\n{test_context}\\n')\n",
    "print(f'Context: \\n{test_tokens}\\n')\n",
    "print(f'Prediction: \\n{ix_to_word[torch.argmax(a[0]).item()]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f81090b-7845-4ece-ac3a-46ccabefbc5d",
   "metadata": {},
   "source": [
    "### word embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d830edad-ed3a-4cf0-8f89-90e82da38a72",
   "metadata": {},
   "source": [
    "查看某一个词的词向量表示，比vocabulary size的长度小了很多(=embedding size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "576224a2-23aa-425e-a363-d683b6e56717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 50])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embedding = model.get_word_emdedding('developments')\n",
    "word_embedding.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
