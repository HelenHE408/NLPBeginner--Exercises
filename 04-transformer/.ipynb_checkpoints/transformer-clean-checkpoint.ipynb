{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b1c0ca7-6141-4f7f-a8da-8fd406c292d3",
   "metadata": {},
   "source": [
    "# lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cf2f86f-0829-4f25-be18-ff1100db4e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe8fbf91-d126-448b-8113-5ac3e92679e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import nltk\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22a9d8cd-4373-4fc6-8175-0c3e9914a8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c0d9886-83fe-4a85-8878-e51a678b6a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1f8fb00-30f4-41cf-8e1a-8317a33037bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "103cc188-8715-4eab-8f4f-9bb6811a869e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afba3b8-e7e0-4c21-8006-c91720bbb7d9",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1abc1d-8d70-4447-a964-802eadf6da00",
   "metadata": {},
   "source": [
    "### data_draft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5defb94f-0566-4489-b455-dcfb8a4c00a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去除标点\n",
    "chi_string = '？！“”。，《》[]〖〗'\n",
    "def dePunctuation(line):\n",
    "    line = line.translate(str.maketrans('', '', string.punctuation))\n",
    "    line = line.translate(str.maketrans('', '', chi_string))\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23e0d6cd-a81c-430c-884a-ee8ca43f9f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    text_new = dePunctuation(text)\n",
    "    return text_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ebd6cb-a477-493c-9b1c-e3917161f91c",
   "metadata": {},
   "source": [
    "English + TAB + The Other Language + TAB + Attribution\n",
    "\n",
    "Attribution包含了来源材料的域名、句子的ID号以及句子所有者的用户名，可以直接忽略"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "246dd1cb-e325-4e4b-b697-31143f41dc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"fra_clean.txt\", \"r\")\n",
    "ori_text = []\n",
    "for line in file:\n",
    "    ori_text.append(line.strip())\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9dac444c-ead7-4253-8273-3b9569da553b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为了减少运算量少取几行\n",
    "raw_text = [ori_text[i] for i in range(2000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f06687f-0866-46e8-92e0-9256cc868db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Go.\\tVa !\\tGo.\\tMarche.\\tGo.\\tEn route !\\tGo.\\t'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = '\\t'.join(raw_text)\n",
    "lines[0:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb68ff22-c279-4866-9c19-d57679deb015",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clean = clean(lines)\n",
    "text_clean = text_clean.split('\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "257e1df3-ad49-4763-a3d4-937002e90e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [line.split('\\t') for line in text_clean]\n",
    "corpus = [word.split() for line in corpus for word in line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ba88515-8784-4219-bea4-c304098a9382",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_en = corpus[0::2]\n",
    "corpus_de = corpus[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ed82d74-3527-4d31-9b81-d3c0a6ab1de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_vocab(corpus):\n",
    "    vocab = [word for line in corpus for word in line]\n",
    "    vocab = set(vocab)\n",
    "    vocab_size = len(vocab)\n",
    "        \n",
    "    return vocab, vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "562cc60c-3c98-48e2-abcc-850c8edf72b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_en, vocab_size_en = make_vocab(corpus_en)\n",
    "vocab_de, vocab_size_de = make_vocab(corpus_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db4658a1-98fa-4ba4-8257-7df835b3e66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx_en = {word:i for i, word in enumerate(vocab_en)}\n",
    "idx2word_en = {i:word for i, word in enumerate(vocab_en)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f4fa2db-c587-4359-9108-95cd0a931a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 570])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_nan = torch.zeros((1, vocab_size_en), dtype=torch.float32)\n",
    "en_nan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b38b6e72-89d0-40cf-baee-86cc7cfef9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx_de = {word:i for i, word in enumerate(vocab_de)}\n",
    "idx2word_de = {i:word for i, word in enumerate(vocab_de)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b630c2-92c1-48d2-8eb1-894c235051b8",
   "metadata": {},
   "source": [
    "encoder和decoder的词要分开编码：因为decoder时，生成的词必须是目标语言"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e8dbe9-fbd3-4dfb-9c7e-260686d01b29",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e6515f-b8c4-4299-a146-817ed5aaba7e",
   "metadata": {},
   "source": [
    "## 试一个sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35f7abf-f8ac-4455-b088-143840b51dfd",
   "metadata": {},
   "source": [
    "### data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca0080ea-cae4-4e6e-87bf-96a2b6ab292f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = text_clean[0::2]\n",
    "decoder = text_clean[1::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555776b5-4074-4226-ba29-7441f082662b",
   "metadata": {},
   "source": [
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f968720-4836-46d9-b15b-fea40f882ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = len(encoder)\n",
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "527f42a4-6077-4c43-9949-c8cb48ec1c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_lines = [line.split() for line in encoder]\n",
    "seq_length = max(len(line) for line in encoder_lines)\n",
    "seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b14db287-e5a0-448a-896e-0fba672f4801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoder_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cad333f4-e4e1-4610-9522-529785992c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4 entries, 0 to 3\n",
      "Columns: 2000 entries, 0 to 1999\n",
      "dtypes: object(2000)\n",
      "memory usage: 62.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# 创建df,batch_szie行, seq_length列\n",
    "df = pd.DataFrame(index=range(seq_length), columns=range(batch_size))\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f7cc766c-b692-4ed6-9a55-1af6e2bf6882",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(encoder_lines)\n",
    "df = df.map(lambda x: word2idx_en.get(x) if x in word2idx_en else -1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a95c12b7-8840-407e-a10b-b5b099f1cb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = df.to_numpy()\n",
    "\n",
    "new_array = np.empty((seq_length,batch_size,vocab_size_en))\n",
    "\n",
    "for a in range(len(array)):\n",
    "    new_array[a] = np.eye(vocab_size_en)[array[a]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80b28213-97e2-40c6-8d98-db07d1ebfa04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2000, 4, 570])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_tensor = torch.from_numpy(new_array).to(torch.float32).transpose(0,1)\n",
    "encoder_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "944f1d23-5711-48b0-9937-f4eb27fdf492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2000, 4, 570])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 删除最后一个维度的最后一列，因为最后一列是-1填充的nan值\n",
    "if encoder_tensor.shape[-1]%2 == 0:\n",
    "    encoder_tensor[:, :, -1] = 0\n",
    "else:\n",
    "    encoder_tensor = encoder_tensor[:, :, :-1]\n",
    "    \n",
    "encoder_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2749f6f-2365-40e4-b257-16a344b5eded",
   "metadata": {},
   "source": [
    "data from Data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a59aea1b-50ca-4458-b590-462d325b1b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Data.Data('fra_clean.txt',2000)\n",
    "\n",
    "# encoder\n",
    "corpus_tensor_en, vocab_size_en, word2idx_en, idx2word_en = corpus.encoder()\n",
    "\n",
    "# decoder\n",
    "corpus_tensor_de, vocab_size_de, word2idx_de, idx2word_de = corpus.decoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a32de13-11f1-4eeb-b38a-fe8ce03a6f28",
   "metadata": {},
   "source": [
    "batch_size, seq_len, vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3397730-3e20-49ed-b258-0af8186cf280",
   "metadata": {},
   "source": [
    "### encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d78bdc-5643-44d3-8993-0e8e04469894",
   "metadata": {},
   "source": [
    "inputs\n",
    "\n",
    "1. 不考虑降维的话，embedding层可以用独热编码\n",
    "2. 位置编码方法：每个位置对应一个d维向量(vocab_size)；为正弦和余弦对；\n",
    "   \n",
    "   p_t = [sin(w_1 * t), cos(w_1 * t), sin(w_2 * t), cos(w_2 * t), ... , sin(w_d/2 * t), cos(w_d/2 * t)], 共d/2 *2 维，d需要能被2整除。\n",
    "   \n",
    "   w_k = 1/(10000^2k/d)\n",
    "\n",
    "   整个position encoding的维度为seq_length * vocab_size\n",
    "\n",
    "   位置编码是固定的，使用register_buffer：PyTorch中nn.Module类的一个方法，用于注册一个不需要进行训练的缓冲张量（buffer tensor）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dda5e4-321b-44c9-9c82-c90bb5363632",
   "metadata": {},
   "source": [
    "Q, K, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8cdcfdf-07a9-4053-a1a0-709b831c2ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Weights(nn.Module):\n",
    "    def __init__(self, hidden_size, input_size, num_heads):\n",
    "        super(Weights, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.num_heads = num_heads\n",
    "        \n",
    "        # Q, K, V，Q = inputs * W_Q\n",
    "        self.W_Q = nn.Linear(input_size, hidden_size)\n",
    "        # k, v的维度需要一致；为了计算方便，将此处Q的维度也设为input_s\n",
    "        self.W_K = nn.Linear(input_size, hidden_size)\n",
    "        self.W_V = nn.Linear(input_size, hidden_size)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "\n",
    "        batch_size, seq_length, _ = inputs.shape\n",
    "        hidden_size = self.hidden_size\n",
    "        num_heads = self.num_heads\n",
    "        \n",
    "        Q = self.W_Q(inputs)\n",
    "        V = self.W_V(inputs)\n",
    "        K = self.W_K(inputs)\n",
    "\n",
    "        # multi-head\n",
    "        Q = Q.view(batch_size, -1, seq_length, hidden_size//num_heads)\n",
    "        V = V.view(batch_size, -1, seq_length, hidden_size//num_heads)\n",
    "        K = K.view(batch_size, -1, seq_length, hidden_size//num_heads).transpose(-1,-2)\n",
    "            \n",
    "        return Q, V, K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80ae0091-1bd2-4a22-a8f8-653514159838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2000, 4, 570])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_tensor_en.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0e0ad64-51c6-4d9c-8041-1f225d14e474",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 128\n",
    "input_size = 570\n",
    "num_heads = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34450d6f-6ae5-4a0b-a7bf-1ed92a63c287",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = Weights(hidden_size, input_size, num_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76d892e9-b07e-4137-83af-bae4faafaccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q, V, K = weights(corpus_tensor_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46f8572c-1cb6-4ec0-a8d5-2dd0d3217d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2000, 2, 4, 64])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "289d8f5e-2c4b-4529-a773-b3b8258b7269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2000, 2, 4, 64])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62d8825e-e707-48ed-ac0e-8332b87e04b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2000, 2, 64, 4])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d59f88e-3559-44b6-b686-efa63a77bff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = torch.matmul(Q, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d20f073-4524-4da1-b733-8eebe32d8e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2000, 2, 4, 4])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a76c9d6d-d9a3-48e3-9d45-971d2046612b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2000, 4, 570])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_tensor_en.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ff46046-cf69-41af-8aad-df7d872eec7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Attention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, Q, K, V, mask = False):\n",
    "\n",
    "        batch_size, seq_length, _, _ = Q.shape\n",
    "        hidden_size = self.hidden_size\n",
    "\n",
    "        # scaled scores\n",
    "        e = torch.matmul(Q, K)/ math.sqrt(hidden_size)\n",
    "\n",
    "        # mask\n",
    "        if mask:\n",
    "            e.masked_fill_(torch.triu(torch.ones_like(e), diagonal=1) == 1, float(\"-inf\"))\n",
    "\n",
    "        # attention_distribution\n",
    "        softmax = self.softmax\n",
    "        a = softmax(e)\n",
    "\n",
    "        # output\n",
    "        o = torch.matmul(a,V)\n",
    "        o = o.view(batch_size, seq_length, hidden_size)\n",
    "            \n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "94316dbc-a2d3-4393-b85c-72ceeefd096c",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = Attention(hidden_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e0e19868-feb2-4e8d-9a1a-cb19b1f07797",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected size for first two dimensions of batch2 tensor to be: [4000, 64] but got: [4000, 4].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m o \u001b[38;5;241m=\u001b[39m \u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mQ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mV\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[22], line 15\u001b[0m, in \u001b[0;36mAttention.forward\u001b[0;34m(self, Q, K, V, mask)\u001b[0m\n\u001b[1;32m     13\u001b[0m K \u001b[38;5;241m=\u001b[39m K\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# scaled scores\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m e \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mQ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m/\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(hidden_size)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# mask\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected size for first two dimensions of batch2 tensor to be: [4000, 64] but got: [4000, 4]."
     ]
    }
   ],
   "source": [
    "o = attention(Q, K, V)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae02bb5e-3eb6-4c8a-981a-778ed8b60608",
   "metadata": {},
   "source": [
    "#### embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "72cb9216-af05-4725-a18c-5e12457d599a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = corpus_tensor_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f428ae6a-9529-4511-8570-9b8ddef3e5dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2000, 4, 570])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7c8f540a-ad62-4c25-bb1a-b4624148bd78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][0][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "26b66c0b-23d4-45d4-a980-32034376edfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "570"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = x.shape[-1]\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eb28a424-981f-4916-b52f-27813cad125c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = nn.Linear(d,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "74132fa5-3941-4838-99d2-d04c6a63c3a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2000, 4, 570])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = embedding(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6c6aaa2f-8671-45ec-bdda-809bdadb6b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0092, -0.0451,  0.0186, -0.0702,  0.0322,  0.0152, -0.0232,  0.0250,\n",
       "         0.0185, -0.0034], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0][0][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f013c06-8b9b-4972-a60b-40319092ef9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 570])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embedding\n",
    "emb_x = x\n",
    "emb_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a75584ed-4fa2-4b66-88fd-1da330f4ce5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 570])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_encode = Position.Encode()\n",
    "p = position_encode.get_position(emb_x.shape)\n",
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0104da38-db6f-498b-8385-61140059a9b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 570])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine\n",
    "inputs = (p + emb_x)\n",
    "inputs.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c784fde7-e57b-4d8b-8714-fbf544b000cc",
   "metadata": {},
   "source": [
    "class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e5ddcef0-300b-472d-ad88-b2b92d83e9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_embedding = Model.PositionEmbedding(corpus_tensor_en.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "da012fa1-49e5-4022-a342-48faca463fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = position_embedding(corpus_tensor_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ec113c79-bc6f-4fa0-8d03-87168cdebc4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2000, 4, 570])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3250912-bcb2-4685-9541-962601502c96",
   "metadata": {},
   "source": [
    "#### attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81715aab-faab-42bb-906b-abdd6b01c390",
   "metadata": {},
   "source": [
    "batch_size, num_heads, seq_length, hidden_size/num_heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ba4e074c-f2fa-472f-8c34-3c7448ecd7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_size_en = vocab_size_en\n",
    "hidden_size =128\n",
    "num_heads = 4\n",
    "batch_size, seq_length, input_size = inputs.shape\n",
    "multi_attention = MultiAttention.MultiAttention(hidden_size, input_size, num_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5b7ecb7b-2458-4829-bb95-991171d485cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = multi_attention(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a98e48dd-0639-4321-888c-a7dee7ff7335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 128])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e68cce26-9c25-434c-a618-808aa7f9c8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(inputs, hidden_size, num_heads):\n",
    "    batch_size, seq_length, input_size = inputs.shape\n",
    "    multi_attention = Model.MultiAttention(hidden_size, input_size, num_heads)\n",
    "    o = multi_attention(inputs)\n",
    "    return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4b5ef13-c422-4ba8-a176-0163ccaec9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size =128\n",
    "num_heads = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eec7775c-9443-469f-94ff-a89f62a3e42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = attention(inputs, hidden_size, num_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5498cbb7-4e68-409a-abeb-88f9fc8dd489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2000, 4, 128])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639e5793-a86f-48c4-be7a-9c9b75a510a9",
   "metadata": {},
   "source": [
    "每个token的attention output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408cc0d8-27a4-449c-915f-a7d29b2f1aa7",
   "metadata": {},
   "source": [
    "#### feed froward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2410c6bb-02a1-4170-b5b8-ec593db60b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_size = o.shape[-1]\n",
    "ff_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "21428474-70c8-4664-8b23-653732ec9c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "feedforward = FeedForward.FeedForward(attn_size, ff_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f3fd561e-a8b1-4d2a-8c08-df9053916a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = feedforward.forward(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bafb332c-8b05-43a0-b787-c10625e8a430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 128])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d8d4af9-5ce2-4b9b-9cb4-cbbd7dc77e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedforward(o, ff_size):\n",
    "    attn_size = o.shape[-1]\n",
    "    feedforward = Model.FeedForward(attn_size, ff_size)\n",
    "    x = feedforward.forward(o)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1951dcb-be91-4c85-991e-0bf50e5a2286",
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8eeda00-b7e1-446b-8826-f6e393122609",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = feedforward(o, ff_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9e9a5ca-767d-4ed1-8313-133a391dfd7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2000, 4, 128])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d2a9f9-1e88-4ff9-9da2-2969a56bacd6",
   "metadata": {},
   "source": [
    "#### linear and softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f6efef5-db04-4f11-ab15-6e8c5f88209e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Outputs(nn.Module):\n",
    "    def __init__(self, ff_size, vocab_size):\n",
    "        super(Outputs, self).__init__()\n",
    "        self.linear = nn.Linear(ff_size, vocab_size)\n",
    "        self.softmax = nn.Softmax(dim =-1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44f70fc0-9086-4893-8c1a-cfc30bcb3e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = Outputs(ff_size=100, vocab_size=vocab_size_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c8a3690-20f9-44ff-809a-edb11f9e52c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = outputs(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d32fc48f-deec-4d57-bf7f-4f25754f32f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2000, 4, 570])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c8e74209-1861-4e76-963b-685354b60e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = nn.Linear(128,vocab_size_en)\n",
    "softmax = nn.Softmax(dim =-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "67576948-0f26-4fcc-b895-9914f12cad0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aeb7c326-13c7-4363-a2ee-589c26b958da",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = softmax(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "732552ad-3bfe-456c-999c-d69584274e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2000, 4, 570])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f709d2-657d-4dca-aad3-16e0165a0bff",
   "metadata": {},
   "source": [
    "#### encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b006b0-9abc-4288-ace4-ac953f711441",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Components\n",
    "\n",
    "encoder = Components.Encoder(corpus_tensor_en, hidden_size = 128, num_heads = 4, ff_size = 100)\n",
    "\n",
    "x = encoder.ff\n",
    "\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f887b33-2b52-4be1-966b-bfe4141e286c",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dea1657-8f90-4953-b960-3085dd03843d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f257a22-9e43-48b3-af73-30f7086c28da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6311cda6-c522-454b-a81a-5623ce5c6bca",
   "metadata": {},
   "source": [
    "## 类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffd98be-17b6-4eef-976b-834e2e03b045",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__():\n",
    "\n",
    "    def forward():\n",
    "\n",
    "    def encoder():\n",
    "\n",
    "    def decoder():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef30344d-4c9f-4d7a-a2ca-799890668638",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3413706-5ff4-4eee-9080-6f78b713d24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ed994e-6cfb-4301-a0d6-33e4ccbbe462",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
